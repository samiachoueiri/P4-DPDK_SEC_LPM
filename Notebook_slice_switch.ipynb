{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02b5308-1775-4cfe-9f4f-eb336a851337",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 1:  Configuring the environment\n",
    "\n",
    "Before running this notebook, you will need to configure your environment using the [Configure Environment](../../../configure_and_validate.ipynb) notebook. Please stop here, open and run that notebook, then return to this notebook.\n",
    "\n",
    "If you are using the FABRIC JupyterHub many of the environment variables will be automatically configured for you.  You will still need to set your bastion username, upload your bastion private key, and set the path to where you put your bastion private key. Your bastion username and private key should already be in your possession.  \n",
    "\n",
    "If you are using the FABRIC API outside of the JupyterHub you will need to configure all of the environment variables. Defaults below will be correct in many situations but you will need to confirm your configuration.  If you have questions about this configuration, please contact the FABRIC admins using the [FABRIC User Forum](https://learn.fabric-testbed.net/forums/) \n",
    "\n",
    "More information about accessing your experiments through the FABRIC bastion hosts can be found [here](https://learn.fabric-testbed.net/knowledge-base/logging-into-fabric-vms/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b571c06-bfd5-464a-acf4-d28845c8e840",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Import the FABlib library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9c3ea6-f0b5-4e34-9a4c-82785ff386c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2913e89-4188-4ebf-a24c-01cedd16540b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Create the experiment slice\n",
    "\n",
    "The following creates three nodes with basic compute and networking capabilities. You build a slice by creating a new slice and adding resources to the slice. After you build the slice, you must submit a request for the slice to be instantiated.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161198e4-00b0-4994-9de8-28e8bfb16cc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.1: Create a slice\n",
    "The code below creates a new slice with the name \"P4DPDK_SYN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c97d810-ac6a-4c04-892d-f0ddbe69954b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice = fablib.new_slice(name=\"P4DPDK_HH4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f228eb-d12b-4644-bbc4-df2e34bbdce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.2: Define the sites\n",
    "The code below requests three random sites from FABRIC based on the condition that the following resources are available:\n",
    "\n",
    "<ul>\n",
    "    <li> 1 SmartNIC</li>\n",
    "    <li> 8 CPU cores</li>\n",
    "    <li> 8GB RAM </li>\n",
    "    <li> 20GB disc size\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28e0cf1-241d-4257-afbf-6aa44989d995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected sites are GATECH, SEAT and ATLA\n"
     ]
    }
   ],
   "source": [
    "# sites= fablib.get_random_sites(count=3, filter_function=lambda x: x['nic_connectx_6_available'] > 1 and x['cores_available'] > 8 and x['ram_available'] > 8 and x['disk_available'] > 20)\n",
    "sites = ['GATECH','SEAT','ATLA']\n",
    "print (f'The selected sites are {sites[0]}, {sites[1]} and {sites[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7713728b-2740-4e72-b5dd-7d3963012536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server1 = slice.add_node(name=\"server1\", \n",
    "                      site=sites[0], \n",
    "                      cores=32, \n",
    "                      ram=64, \n",
    "                      disk=60, \n",
    "                      image='default_ubuntu_20')\n",
    "server2 = slice.add_node(name=\"server2\", \n",
    "                      site=sites[0], \n",
    "                      cores=32, \n",
    "                      ram=64, \n",
    "                      disk=60, \n",
    "                      image='default_ubuntu_20')\n",
    "\n",
    "switch = slice.add_node(name=\"switch\", \n",
    "                      site=sites[2], \n",
    "                      cores=32, \n",
    "                      ram=16, \n",
    "                      disk=40, \n",
    "                      image='default_ubuntu_20')\n",
    "\n",
    "server3 = slice.add_node(name=\"server3\", \n",
    "                      site=sites[2], \n",
    "                      cores=8, \n",
    "                      ram=8, \n",
    "                      disk=20, \n",
    "                      image='default_ubuntu_20')\n",
    "server4 = slice.add_node(name=\"server4\", \n",
    "                      site=sites[2], \n",
    "                      cores=8, \n",
    "                      ram=8, \n",
    "                      disk=20, \n",
    "                      image='default_ubuntu_20')\n",
    "server5 = slice.add_node(name=\"server5\", \n",
    "                      site=sites[2], \n",
    "                      cores=8, \n",
    "                      ram=8, \n",
    "                      disk=20, \n",
    "                      image='default_ubuntu_20')\n",
    "server6 = slice.add_node(name=\"server6\", \n",
    "                      site=sites[2], \n",
    "                      cores=8, \n",
    "                      ram=8, \n",
    "                      disk=20, \n",
    "                      image='default_ubuntu_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f08e680-9922-4517-8f87-99e86ed455be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server1_iface = server1.add_component(model='NIC_ConnectX_6', name='nic1').get_interfaces()[0]\n",
    "\n",
    "server2_1_iface = server2.add_component(model='NIC_ConnectX_6', name='nic2').get_interfaces()[0]\n",
    "server2_s_iface = server2.get_component(name='nic2').get_interfaces()[1]\n",
    "\n",
    "switch_2_iface = switch.add_component(model='NIC_ConnectX_6', name='nicS2').get_interfaces()[0]\n",
    "# server2_s_iface = server2.get_component(name='nic2').get_interfaces()[1]_s_iface = server2.get_component(name='nic2').get_interfaces()[1]\n",
    "switch_3_iface = switch.add_component(model='NIC_Basic', name='nicS3').get_interfaces()[0]\n",
    "switch_4_iface = switch.add_component(model='NIC_Basic', name='nicS4').get_interfaces()[0]\n",
    "switch_5_iface = switch.add_component(model='NIC_Basic', name='nicS5').get_interfaces()[0]\n",
    "switch_6_iface = switch.add_component(model='NIC_Basic', name='nicS6').get_interfaces()[0]\n",
    "\n",
    "server3_iface = server3.add_component(model='NIC_Basic', name='nic3').get_interfaces()[0]\n",
    "server4_iface = server4.add_component(model='NIC_Basic', name='nic4').get_interfaces()[0]\n",
    "server5_iface = server5.add_component(model='NIC_Basic', name='nic5').get_interfaces()[0]\n",
    "server6_iface = server6.add_component(model='NIC_Basic', name='nic6').get_interfaces()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ca24e-8743-4d4a-91ea-128dd78b4273",
   "metadata": {},
   "source": [
    "### Step 3.5: Connecting server1 and server2\n",
    "Create a network between server1 and server2 connecting them together and a network between server2 and server3 connecting them together.\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/05_connecting_nodes.png\" width=\"550\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03859457-746d-402c-9372-9803df8928e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = slice.add_l2network(name='net1', interfaces=[server1_iface, server2_1_iface])\n",
    "net2 = slice.add_l2network(name='net2', interfaces=[server2_s_iface, switch_2_iface])\n",
    "net3 = slice.add_l2network(name='net3', interfaces=[server3_iface, switch_3_iface])\n",
    "net4 = slice.add_l2network(name='net4', interfaces=[server4_iface, switch_4_iface])\n",
    "net5 = slice.add_l2network(name='net5', interfaces=[server5_iface, switch_5_iface])\n",
    "net6 = slice.add_l2network(name='net6', interfaces=[server6_iface, switch_6_iface])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab345c-d68e-440d-9fda-03d67472f1ca",
   "metadata": {},
   "source": [
    "### Step 3.6: Submitting the slice\n",
    "The code below submits the slice. \n",
    "By default, the submit function will block until the node is ready and will display the progress of your slice being built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e706c53c-7a38-4615-a86e-e8944197921f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mslice\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/slice.py:2499\u001b[0m, in \u001b[0;36mSlice.submit\u001b[0;34m(self, wait, wait_timeout, wait_interval, progress, wait_jupyter, post_boot_config, wait_ssh, extra_ssh_keys, lease_start_time, lease_end_time, lease_in_hours, validate)\u001b[0m\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   2489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to submit slice: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2490\u001b[0m             return_status, slice_reservations\n\u001b[1;32m   2491\u001b[0m         )\n\u001b[1;32m   2492\u001b[0m     )\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2495\u001b[0m     progress\n\u001b[1;32m   2496\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m wait_jupyter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2497\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfablib_manager\u001b[38;5;241m.\u001b[39mis_jupyter_notebook()\n\u001b[1;32m   2498\u001b[0m ):\n\u001b[0;32m-> 2499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_jupyter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_boot_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_boot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_id\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m wait:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/slice.py:2206\u001b[0m, in \u001b[0;36mSlice.wait_jupyter\u001b[0;34m(self, timeout, interval, verbose, post_boot_config)\u001b[0m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec exceeded in Jupyter wait\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2206\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2208\u001b[0m stable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m allocated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfa5ff-9374-4823-9ea0-09f045a91684",
   "metadata": {},
   "source": [
    "# Step 4: Installing the required packages\n",
    "In this step, we will install the required packages to run the lab. Specifically, we will install the Mellanox drivers, DPDK library, the P4 compiler (p4c), and all needed dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c40316-489b-428d-82de-eb92e87c87dc",
   "metadata": {},
   "source": [
    "## Step 4.1 Appending list of servers\n",
    "All servers are appended to a list to execute commands in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61333554-ef05-480e-bee6-c2a035213b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "servers = []\n",
    "\n",
    "servers.append(slice.get_node(name=\"server1\"))     \n",
    "servers.append(slice.get_node(name=\"server2\"))\n",
    "servers.append(slice.get_node(name=\"switch\"))     \n",
    "servers.append(slice.get_node(name=\"server3\"))\n",
    "servers.append(slice.get_node(name=\"server4\"))     \n",
    "servers.append(slice.get_node(name=\"server5\"))     \n",
    "servers.append(slice.get_node(name=\"server6\"))     \n",
    "\n",
    "server1 = servers[0]\n",
    "server2 = servers[1]\n",
    "switch = servers[2]\n",
    "server3 = servers[3]\n",
    "server4 = servers[4]\n",
    "server5 = servers[5]\n",
    "server6 = servers[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6f042-3232-4245-9a5b-9e163b1bb8f4",
   "metadata": {},
   "source": [
    "## Step 4.2 NAT64 setup\n",
    "The code below checks if an IPv6 address is available to set up NAT64. We will upload the script [scripts/nat64.sh](./scripts/nat64.sh) to the all servers and execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00430e7b-472e-4d5b-a81d-03dfaaec14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv6Address\n",
    "\n",
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    if type(ip_address(server.get_management_ip())) is IPv6Address:\n",
    "        server.upload_file('scripts/nat64.sh', 'nat64.sh')\n",
    "        threads.append(server.execute_thread(f'chmod +x nat64.sh && ./nat64.sh'))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c187536-f87c-47ae-9ced-9cf234f70c45",
   "metadata": {},
   "source": [
    "## Step 4.3 Installing dependencies\n",
    "The code below installs packages that are prerequisites to the upcoming installations and needed to run the lab experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d516e3-323e-44c7-bec8-45a2d48a0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    threads.append(server.execute_thread('''\n",
    "        sudo apt-get update;\n",
    "        sudo apt-get install -y build-essential python3-pip python3-pyelftools libnuma-dev pkg-config net-tools hping3;\n",
    "        sudo pip3 install meson ninja\n",
    "    '''))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf4d2f-0ba4-4629-b221-87b19d4c0324",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.4 Installing Mellanox drivers\n",
    "Since ConnectX-6 NICs are used in this lab, it is essential to install the supporting drivers. The code below downloads and installs Mellanox drivers on all servers while enabling DPDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa0c8d8-5d49-44cb-8d0a-1feb391fa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    threads.append(server.execute_thread('''\n",
    "        wget https://content.mellanox.com/ofed/MLNX_OFED-23.07-0.5.0.0/MLNX_OFED_LINUX-23.07-0.5.0.0-ubuntu20.04-x86_64.tgz; \n",
    "        tar xvfz MLNX_OFED_LINUX-23.07-0.5.0.0-ubuntu20.04-x86_64.tgz; \n",
    "        cd MLNX_OFED_LINUX-23.07-0.5.0.0-ubuntu20.04-x86_64; \n",
    "        echo \"y\" | sudo ./mlnxofedinstall --upstream-libs --dpdk --basic --without-fw-update --enable-sriov --hypervisor\n",
    "    '''))\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea007d60-a00c-4c48-aab9-a9dc3ef16931",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.5 Installing DPDK\n",
    "The code below downloads, builds, and installs DPDK on all servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38ccab6-c61e-43ed-a819-452be4b2a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    threads.append(server.execute_thread('''\n",
    "        git clone http://dpdk.org/git/dpdk; \n",
    "        cd dpdk;\n",
    "        sudo meson build;\n",
    "        cd build;\n",
    "        sudo ninja;\n",
    "        sudo ninja install; \n",
    "        sudo ldconfig\n",
    "    '''))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd506e1-57d7-4253-817b-613ebfe68e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdout, stderr = server2.execute(f'cd dpdk/lib/pipeline/ &&  sudo rm rte_swx_pipeline.c && sudo rm rte_swx_pipeline_internal.h', quiet = True)\n",
    "# server2.upload_file('scripts/rte_swx_pipeline.c','/home/ubuntu/dpdk/lib/pipeline/rte_swx_pipeline.c')\n",
    "# server2.upload_file('scripts/rte_swx_pipeline_internal.h','/home/ubuntu/dpdk/lib/pipeline/rte_swx_pipeline_internal.h')\n",
    "# stdout, stderr = server2.execute(f'cd dpdk && cd build && sudo ninja && sudo ninja install && sudo ldconfig', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def48d5-9ba4-42f0-964a-054a40237266",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.6 Installing Pktgen\n",
    "In this lab, we will send from server1 packets at a high rate to server2 using a DPDK-based packet generation tool called pktgen [<a href=\"#References\">5</a>]. The code below downloads and installs Pktgen-DPDK on all servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af364204-2c14-480d-ac8c-ad025339c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    threads.append(server.execute_thread('''\n",
    "        sudo git clone https://github.com/pktgen/Pktgen-DPDK; \n",
    "        sudo sed -i \\\"s/deps += \\\\[dependency('numa', required: true)\\\\]/deps += \\\\[dependency('numa', required: false)\\\\]/\\\" /home/ubuntu/Pktgen-DPDK/app/meson.build;\n",
    "        sudo apt-get install -y cmake libpcap-dev libbsd-dev;\n",
    "        cd Pktgen-DPDK &&  sudo meson build && sudo ninja -C build && cd build/ && sudo meson install\n",
    "    '''))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb2d4b-3b36-4c1d-b000-f1da0d1f7055",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.7 Build pipeline library\n",
    "The code below builds the DPDK pipeline library in server 2 (on which the pipeline will be running) to put all its functions into effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eabfb81a-869f-4768-8d86-20472aa4297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server2.execute(f'cd dpdk/examples/pipeline && sudo make', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3663be2-ae7e-4352-9659-4ac52b2b32b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.8 Install p4c\n",
    "The code below downloads and installs the p4c compiler needed to compile the p4 code into a DPDK pipeline. In this lab, p4c is built from a version where the architecture has been modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19257d0a-b1b2-4721-8c9f-422014ab53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server2.execute('git clone https://github.com/CILab-USC/p4c.git', quiet = True)\n",
    "stdout, stderr = server2.execute('sudo apt-get install -y cmake g++ git automake libtool libgc-dev bison flex libfl-dev libboost-dev libboost-iostreams-dev libboost-graph-dev llvm pkg-config python3 python3-pip tcpdump', quiet = True)\n",
    "stdout, stderr = server2.execute('cd p4c && pip3 install --user -r requirements.txt && mkdir build && cd build && cmake .. && make -j4  && sudo make install', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1027af7-48ef-4e8b-b57f-fc228f33ee11",
   "metadata": {},
   "source": [
    "Switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87a9e0b7-56b9-47bd-b4e1-6715fdb3609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch = slice.get_node(name=\"switch\")     \n",
    "switch.upload_file('main/scripts/install_bmv2.sh', 'install_bmv2.sh')\n",
    "stdout, stderr = switch.execute(f'chmod +x install_bmv2.sh &&  ./install_bmv2.sh',quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94197771-e620-48f3-80f2-9cab71f48542",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4.9 Reboot\n",
    "After installing the ConnectX Mellanox divers, it is essential to reboot the servers to complete the installation process or to ensure that updates are applied correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b4307ef-2dbe-465b-969c-2a82a82fa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for server in servers:\n",
    "    server.os_reboot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c7395-b469-4ebc-9fc3-8f0834ddf676",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 5: Configuring Network\n",
    "In this step, we will assign IPv4 addresses to the interfaces of the servers and hardcode the MAC addresses. We will also configure forwarding and routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3b0d19-c55b-43e5-98b1-cea0fccec6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server1_iface: enp7s0np0\n",
      "server2_iface1: enp7s0np0\n",
      "server2_iface2: enp8s0np1\n",
      "switch_iface: enp9s0np0\n",
      "switch_iface3: enp7s0np0\n",
      "switch_iface4: enp11s0np0\n",
      "switch_iface5: enp8s0np0\n",
      "switch_iface6: enp12s0np0\n",
      "server3_iface: enp7s0np0\n",
      "server4_iface: enp7s0np0\n",
      "server5_iface: enp7s0np0\n",
      "server6_iface: enp7s0np0\n"
     ]
    }
   ],
   "source": [
    "node1_iface = server1.get_interface(network_name='net1') \n",
    "server1_iface_name = node1_iface.get_device_name()+'np0'\n",
    "print(f'server1_iface: {server1_iface_name}')\n",
    "\n",
    "node2_iface1 = server2.get_interface(network_name='net1') \n",
    "server2_iface1_name = node2_iface1.get_device_name()+'np0'\n",
    "print(f'server2_iface1: {server2_iface1_name}')\n",
    "node2_iface2 = server2.get_interface(network_name='net2') \n",
    "server2_iface2_name = node2_iface2.get_device_name()+'np1'\n",
    "print(f'server2_iface2: {server2_iface2_name}')\n",
    "\n",
    "switch_iface = switch.get_interface(network_name='net2') \n",
    "switch_iface_name = switch_iface.get_device_name()+'np0'\n",
    "print(f'switch_iface: {switch_iface_name}')\n",
    "switch_iface3 = switch.get_interface(network_name='net3') \n",
    "switch_iface3_name = switch_iface3.get_device_name()+'np0'\n",
    "print(f'switch_iface3: {switch_iface3_name}')\n",
    "switch_iface4 = switch.get_interface(network_name='net4') \n",
    "switch_iface4_name = switch_iface4.get_device_name()+'np0'\n",
    "print(f'switch_iface4: {switch_iface4_name}')\n",
    "switch_iface5 = switch.get_interface(network_name='net5') \n",
    "switch_iface5_name = switch_iface5.get_device_name()+'np0'\n",
    "print(f'switch_iface5: {switch_iface5_name}')\n",
    "switch_iface6 = switch.get_interface(network_name='net6') \n",
    "switch_iface6_name = switch_iface6.get_device_name()+'np0'\n",
    "print(f'switch_iface6: {switch_iface6_name}')\n",
    "\n",
    "node3_iface = server3.get_interface(network_name='net3') \n",
    "server3_iface_name = node3_iface.get_device_name()+'np0'\n",
    "print(f'server3_iface: {server3_iface_name}')\n",
    "\n",
    "node4_iface = server4.get_interface(network_name='net4') \n",
    "server4_iface_name = node4_iface.get_device_name()+'np0'\n",
    "print(f'server4_iface: {server4_iface_name}')\n",
    "\n",
    "node5_iface = server5.get_interface(network_name='net5') \n",
    "server5_iface_name = node5_iface.get_device_name()+'np0'\n",
    "print(f'server5_iface: {server5_iface_name}')\n",
    "\n",
    "node6_iface = server6.get_interface(network_name='net6') \n",
    "server6_iface_name = node6_iface.get_device_name()+'np0'\n",
    "print(f'server6_iface: {server6_iface_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b5b81d-0748-4469-9199-1b1ac166ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ip link set dev {server1_iface_name} up', quiet=True)\n",
    "stdout, stderr = server2.execute(f'sudo ip link set dev {server2_iface1_name} up', quiet=True)\n",
    "stdout, stderr = server2.execute(f'sudo ip link set dev {server2_iface2_name} up', quiet=True)\n",
    "\n",
    "stdout, stderr = switch.execute(f'sudo ip link set dev {switch_iface_name} up', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo ip link set dev {switch_iface3_name} up', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo ip link set dev {switch_iface4_name} up', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo ip link set dev {switch_iface5_name} up', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo ip link set dev {switch_iface6_name} up', quiet=True)\n",
    "\n",
    "stdout, stderr = server3.execute(f'sudo ip link set dev {server3_iface_name} up', quiet=True)\n",
    "stdout, stderr = server4.execute(f'sudo ip link set dev {server4_iface_name} up', quiet=True)\n",
    "stdout, stderr = server5.execute(f'sudo ip link set dev {server5_iface_name} up', quiet=True)\n",
    "stdout, stderr = server6.execute(f'sudo ip link set dev {server6_iface_name} up', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96f41fe4-6da1-4551-8de8-84125232595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "server1_iface_MAC = '00:00:00:00:00:01' \n",
    "server2_iface1_MAC = '00:00:00:00:00:21' \n",
    "server2_iface2_MAC = '00:00:00:00:00:22' \n",
    "\n",
    "switch_iface_MAC = '00:00:00:00:00:30' \n",
    "switch_iface3_MAC = '00:00:00:00:00:33'\n",
    "switch_iface4_MAC = '00:00:00:00:00:34'\n",
    "switch_iface5_MAC = '00:00:00:00:00:35'\n",
    "switch_iface6_MAC = '00:00:00:00:00:36'\n",
    "\n",
    "server3_iface_MAC = '00:00:00:00:00:03'\n",
    "server4_iface_MAC = '00:00:00:00:00:04'\n",
    "server5_iface_MAC = '00:00:00:00:00:05'\n",
    "server6_iface_MAC = '00:00:00:00:00:06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7340e2cc-f657-41ae-8b78-62c21afed741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ifconfig {server1_iface_name} hw ether {server1_iface_MAC}')\n",
    "stdout, stderr = server2.execute(f'sudo ifconfig {server2_iface1_name} hw ether {server2_iface1_MAC}')\n",
    "stdout, stderr = server2.execute(f'sudo ifconfig {server2_iface2_name} hw ether {server2_iface2_MAC}')\n",
    "\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface_name} hw ether {switch_iface_MAC}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface3_name} hw ether {switch_iface3_MAC}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface4_name} hw ether {switch_iface4_MAC}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface5_name} hw ether {switch_iface5_MAC}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface6_name} hw ether {switch_iface6_MAC}')\n",
    "\n",
    "stdout, stderr = server3.execute(f'sudo ifconfig {server3_iface_name} hw ether {server3_iface_MAC}')\n",
    "stdout, stderr = server4.execute(f'sudo ifconfig {server4_iface_name} hw ether {server4_iface_MAC}')\n",
    "stdout, stderr = server5.execute(f'sudo ifconfig {server5_iface_name} hw ether {server5_iface_MAC}')\n",
    "stdout, stderr = server6.execute(f'sudo ifconfig {server6_iface_name} hw ether {server6_iface_MAC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a809cee-0098-4287-be64-3dae1aad966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "server1_iface_IP = '192.168.10.01/24' \n",
    "server2_iface1_IP = '192.168.10.21/24' \n",
    "server2_iface2_IP = '192.168.20.22/24' \n",
    "\n",
    "switch_iface_IP = '192.168.20.30/24' \n",
    "switch_iface3_IP = '192.168.30.33/24'\n",
    "switch_iface4_IP = '192.168.30.34/24'\n",
    "switch_iface5_IP = '192.168.30.35/24'\n",
    "switch_iface6_IP = '192.168.30.36/24'\n",
    "\n",
    "server3_iface_IP = '192.168.30.03/24'\n",
    "server4_iface_IP = '192.168.30.04/24'\n",
    "server5_iface_IP = '192.168.30.05/24'\n",
    "server6_iface_IP = '192.168.30.06/24'\n",
    "\n",
    "net1_subnet = \"192.168.10.0/24\"\n",
    "net2_subnet = \"192.168.20.0/24\"\n",
    "net3_subnet = \"192.168.30.0/24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e09befad-a977-43d1-a5c7-2ac350967992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ifconfig {server1_iface_name} {server1_iface_IP}')\n",
    "stdout, stderr = server2.execute(f'sudo ifconfig {server2_iface1_name} {server2_iface1_IP}')\n",
    "stdout, stderr = server2.execute(f'sudo ifconfig {server2_iface2_name} {server2_iface2_IP}')\n",
    "\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface_name} {switch_iface_IP}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface3_name} {switch_iface3_IP}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface4_name} {switch_iface4_IP}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface5_name} {switch_iface5_IP}')\n",
    "stdout, stderr = switch.execute(f'sudo ifconfig {switch_iface6_name} {switch_iface6_IP}')\n",
    "\n",
    "stdout, stderr = server3.execute(f'sudo ifconfig {server3_iface_name} {server3_iface_IP}')\n",
    "stdout, stderr = server4.execute(f'sudo ifconfig {server4_iface_name} {server4_iface_IP}')\n",
    "stdout, stderr = server5.execute(f'sudo ifconfig {server5_iface_name} {server5_iface_IP}')\n",
    "stdout, stderr = server6.execute(f'sudo ifconfig {server6_iface_name} {server6_iface_IP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac08f975-729c-4c80-aa58-9dcf8e5ef440",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = server1.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = server2.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = server3.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = server4.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = server5.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = server5.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo sysctl -w net.ipv4.ip_forward=1', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd8a0c6f-7fc5-4711-9636-4d6cb4f1baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      "RTNETLINK answers: File exists\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      "RTNETLINK answers: File exists\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "ip1 = server1_iface_IP.split('/')[0]\n",
    "ip2_1 = server2_iface1_IP.split('/')[0]\n",
    "ip2_2 = server2_iface2_IP.split('/')[0]\n",
    "ips = switch_iface_IP.split('/')[0]\n",
    "ips_3 = switch_iface3_IP.split('/')[0]\n",
    "ips_4 = switch_iface4_IP.split('/')[0]\n",
    "ips_5 = switch_iface5_IP.split('/')[0]\n",
    "ips_6 = switch_iface6_IP.split('/')[0]\n",
    "ip3 = server3_iface_IP.split('/')[0]\n",
    "ip4 = server4_iface_IP.split('/')[0]\n",
    "ip5 = server5_iface_IP.split('/')[0]\n",
    "ip6 = server6_iface_IP.split('/')[0]\n",
    "subnet1 = \"192.168.10.0/24\"\n",
    "subnet2 = \"192.168.20.0/24\"\n",
    "subnet3 = \"192.168.30.0/24\"\n",
    "\n",
    "stdout, stderr = server1.execute(f'sudo arp -s {ip2_1} {server2_iface1_MAC} -i {server1_iface_name}')\n",
    "stdout, stderr = server1.execute(f'sudo ip route add {subnet2} via {ip2_1}')\n",
    "stdout, stderr = server1.execute(f'sudo ip route add {subnet3} via {ip2_1}')\n",
    "\n",
    "stdout, stderr = server2.execute(f'sudo arp -s {ip1} {server1_iface_MAC} -i {server2_iface1_name}')\n",
    "stdout, stderr = server2.execute(f'sudo arp -s {ips} {switch_iface_MAC} -i {server2_iface2_name}')\n",
    "stdout, stderr = server2.execute(f'sudo ip route add {subnet3} via {ips}')\n",
    "\n",
    "ststdout, stderr = switch.execute(f'sudo arp -s {ip2_2} {server2_iface2_MAC} -i {switch_iface_name}')\n",
    "stdout, stderr = switch.execute(f'sudo arp -s {ip3} {server3_iface_MAC} -i {switch_iface3_name}')\n",
    "stdout, stderr = switch.execute(f'sudo arp -s {ip4} {server4_iface_MAC} -i {switch_iface4_name}')\n",
    "stdout, stderr = switch.execute(f'sudo arp -s {ip5} {server5_iface_MAC} -i {switch_iface5_name}')\n",
    "stdout, stderr = switch.execute(f'sudo arp -s {ip6} {server6_iface_MAC} -i {switch_iface6_name}')\n",
    "stdout, stderr = switch.execute(f'sudo ip route add {subnet1} via {ip2_2}')\n",
    "stdout, stderr = switch.execute(f'sudo ip route add {ip3} dev {switch_iface3_name} src {ips_3}')\n",
    "stdout, stderr = switch.execute(f'sudo ip route add {ip4} dev {switch_iface4_name} src {ips_4}')\n",
    "stdout, stderr = switch.execute(f'sudo ip route add {ip5} dev {switch_iface5_name} src {ips_5}')\n",
    "stdout, stderr = switch.execute(f'sudo ip route add {ip6} dev {switch_iface6_name} src {ips_6}')\n",
    "\n",
    "stdout, stderr = server3.execute(f'sudo arp -s {ips_3} {switch_iface3_MAC} -i {server3_iface_name}')\n",
    "stdout, stderr = server3.execute(f'sudo ip route add {subnet1} via {ips_3}')\n",
    "stdout, stderr = server3.execute(f'sudo ip route add {subnet2} via {ips_3}')\n",
    "\n",
    "stdout, stderr = server4.execute(f'sudo arp -s {ips_4} {switch_iface4_MAC} -i {server4_iface_name}')\n",
    "stdout, stderr = server4.execute(f'sudo ip route add {subnet1} via {ips_4}')\n",
    "stdout, stderr = server4.execute(f'sudo ip route add {subnet2} via {ips_4}')\n",
    "\n",
    "stdout, stderr = server5.execute(f'sudo arp -s {ips_5} {switch_iface5_MAC} -i {server5_iface_name}')\n",
    "stdout, stderr = server5.execute(f'sudo ip route add {subnet1} via {ips_5}')\n",
    "stdout, stderr = server5.execute(f'sudo ip route add {subnet2} via {ips_5}')\n",
    "\n",
    "stdout, stderr = server6.execute(f'sudo arp -s {ips_6} {switch_iface6_MAC} -i {server6_iface_name}')\n",
    "stdout, stderr = server6.execute(f'sudo ip route add {subnet1} via {ips_6}')\n",
    "stdout, stderr = server6.execute(f'sudo ip route add {subnet2} via {ips_6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796088b-d77e-44e2-978e-3856e5bc998b",
   "metadata": {},
   "source": [
    "## Step 5.8: Mellanox devices\n",
    "\n",
    "In this step, we will inspect and start all Mellanox devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95959918-3aa1-4fb9-9fc1-6b2cddd12130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "mlx5_1 port 1 ==> enp8s0np1 (Down)\n",
      "\u001b[31m sudo: unable to resolve host server1: Name or service not known\n",
      " \u001b[0mmlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "mlx5_1 port 1 ==> enp8s0np1 (Up)\n",
      "\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0mmlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "mlx5_1 port 1 ==> enp8s0np0 (Up)\n",
      "\u001b[31m sudo: unable to resolve host switch: Name or service not known\n",
      " \u001b[0mmlx5_2 port 1 ==> enp9s0np0 (Up)\n",
      "mlx5_3 port 1 ==> enp10s0np1 (Down)\n",
      "mlx5_4 port 1 ==> enp11s0np0 (Up)\n",
      "mlx5_5 port 1 ==> enp12s0np0 (Up)\n",
      "mlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "\u001b[31m sudo: unable to resolve host server3: Name or service not known\n",
      " \u001b[0mmlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "\u001b[31m sudo: unable to resolve host server4: Name or service not known\n",
      " \u001b[0mmlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "\u001b[31m sudo: unable to resolve host server5: Name or service not known\n",
      " \u001b[0mmlx5_0 port 1 ==> enp7s0np0 (Up)\n",
      "\u001b[31m sudo: unable to resolve host server6: Name or service not known\n",
      " \u001b[0m"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server1.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server1.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server1.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = server2.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server2.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server2.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server2.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = switch.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = switch.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = switch.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = server3.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server3.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server3.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server3.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = server4.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server4.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server4.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server4.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = server5.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server5.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server5.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server5.execute(f'sudo mst status', quiet=True)\n",
    "\n",
    "stdout, stderr = server6.execute(f'sudo ibdev2netdev')\n",
    "stdout, stderr = server6.execute(f'sudo mst status', quiet=True)\n",
    "stdout, stderr = server6.execute(f'sudo mst start', quiet=True)\n",
    "stdout, stderr = server6.execute(f'sudo mst status', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfbd62-5ec4-4926-a449-638ac6de9d2b",
   "metadata": {},
   "source": [
    "In the output above, you can see that there are two interfaces that are turned down. This is because each server has a Connect-X6 NIC attached, which is a dual-port NIC, and only one port in the NICs of server1 and server3 is used in this topology. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3fdb8-da21-474a-b623-b09ac65511ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 6: Implementing the P4 code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f366db9-1d84-41b2-a307-389a62dc146f",
   "metadata": {},
   "source": [
    "## Step 6.1: Modifying the control file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f12598-b9bf-4195-b297-56f0d6ec34e5",
   "metadata": {},
   "source": [
    "Click on [control.p4](./labs_files/SYN/control.p4) to open the CLI file in the editor.\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_00.png\" width=\"650\"><br>\n",
    "We can see that the control.p4 declares a control block named MainControl. Note that we will modify the body of the control block.\n",
    "\n",
    "<hr>\n",
    "\n",
    "In the control.p4 file, define the variable ```THRESH```. ```THRESH``` represents the threshold of received SYN packets per second after which the pipeline will start dropping packets. The threshold is set to 1000000 packets.\n",
    "\n",
    "    #define THRESH 1000000\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_01.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "In the MainControl block, define the register ```drop_percent_reg``` to maintain the percentage of packets to be dropped after the number of received SYN packets increases above the threshold.\n",
    "\n",
    "    Register<bit<7>, bit<1>>(1) drop_percent_reg;\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_02.png\" width=\"650\"><br>\n",
    "\n",
    "The ```Register``` extern creates a register by taking the cell width in bits, 7 bits in this example. The second argument considered by this extern is the number of bits needed to represent the indices of the register, 1 bit in this example. One bit is enough to represent all indices in this register because the length of the register is specified as 1. Finally, the register is associated with a label ```drop_percent_reg```.\n",
    "\n",
    "<div style=\"background-color: #e0f7fa; border: 1px solid #b2ebf2; padding: 10px; border-radius: 5px;\">\n",
    "Note that the p4c-dpdk compiler adds (_0) to the labels of the registers defined in the P4 code. Therefore, drop_percent_reg is compiled as drop_percent_reg_0 in the pipeline. </div>\n",
    "\n",
    "The code above defines a register named drop_percent_reg. The register contains a single cell. The cell stores the percentage of packets to be dropped. This register can be configured from the control plane at runtime to specify the dropping percentage. Because the maximum possible dropping percentage is 100, and 7 is the minimum number of bits needed to represent 100 (since 2^7=128), the size of the register cell is set to 7 bits. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Define the register syn_counts_reg to maintain the count of the received SYN packets.\n",
    "\n",
    "    Register<bit<32>, bit<1>>(1) syn_counts_reg;\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_03.png\" width=\"650\"><br>\n",
    "\n",
    "The code above defines a register named ```syn_counts_reg```. The register contains a single cell. The cell stores the number of received SYN packets. Later, we will be resetting the value of this register to zero; thus, this cell will contain the number of received SYN packets per second. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Define the register percent_iterator_reg to maintain the packet count iterator.\n",
    "\n",
    "    Register<bit<7>, bit<1>>(1) percent_iterator_reg;\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_04.png\" width=\"650\"><br>\n",
    "\n",
    "The code above defines a register named ```percent_iterator_reg```. The register contains a single cell. This cell is used to track how many packets to drop and to allow out of 100.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to the apply block to retrieve the dropping percentage from the register.\n",
    "\n",
    "    if(hdr.tcp.isValid()){\n",
    "        meta.drop_percent = drop_percent_reg.read(0);\n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_05.png\" width=\"650\"><br>\n",
    "\n",
    "The code above defines a register named ```percent_iterator_reg```. The register contains a single cell. This cell is used to track how many packets to drop and to allow out of 100.\n",
    "\n",
    "In the code above, ```if(hdr.tcp.isValid())``` checks if the packet is a TCP packet. For TCP packets, the dropping percentage is retrieved from ```drop_percentage_reg``` and stored in the ```drop_percent``` variable. Note that the dropping percentage will be specified from the control plane.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to check if the incoming packet is a SYN packet.\n",
    "\n",
    "    if(hdr.tcp.flags == 2) {\n",
    "    \n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_06.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to increment the count of SYN packets. \n",
    "    \n",
    "    meta.syn_counts = 0;\n",
    "\n",
    "    meta.syn_counts = syn_counts_reg.read(0);\n",
    "    meta.syn_counts = meta.syn_counts +1;\n",
    "    syn_counts_reg.write(0, meta.syn_counts);\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_07.png\" width=\"650\"><br>\n",
    "\n",
    "```.read``` is a method used to read the value in a register at a specific index. ```.write``` is a method used to write a value to a register at a specific index. In the code above, the count of SYN packets is retrieved from the ```syn_counts_reg``` at index 0 and stored in the ```syn_counts``` variable. The variable is incremented by one to account for the current packet. After that, the updated ```syn_counts``` variable is stored in the ```syn_count_reg``` register at index 0.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to check if the number of SYN packets exceeded THRESH. \n",
    "\n",
    "    if(meta.syn_counts > THRESH){\n",
    "\n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_08.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to retrieve the iterator from the ```percent_iterator_reg```.\n",
    "\n",
    "    meta.percent_iterator = percent_iterator_reg.read(0);\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_09.png\" width=\"650\"><br>\n",
    "\n",
    "In the code above, the iterator is retrieved from ```percent_iterator_reg``` and stored inside the ```percent_iterator``` variable.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to check if the iterator is less than the dropping percentage. \n",
    "\n",
    "    if(meta.percent_iterator < meta.drop_percent){\n",
    "\n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_10.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to drop the packet and increment the iterator if the ```percent_iterator``` is less than the ```drop_percent```.\n",
    "\n",
    "    meta.percent_iterator = meta.percent_iterator + 1;\n",
    "    percent_iterator_reg.write(0, meta.percent_iterator);\n",
    "    drop();\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_11.png\" width=\"650\"><br>\n",
    "\n",
    "In the code above, the ```percent_iterator``` variable is incremented by one and stored in the ```percent_iterator_reg``` register. After that, the packet is dropped.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to increment the count of dropped packets by one without dropping the packet if the number of dropped packet is less than 100.\n",
    "\n",
    "    else if (meta.percent_iterator < 100) {\n",
    "       meta.percent_iterator = meta.percent_iterator + 1;\n",
    "       percent_iterator_reg.write(0, meta.percent_iterator);\n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_12.png\" width=\"650\"><br>\n",
    "\n",
    "From each 100 packets, we are dropping the first ```drop_percent``` packets (e.g., the first 50 packets if the ```drop_percen```t is 50%). The remaining packets (i.e., 100  ```drop_percent```) are forwarded.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Add the following code to reset ```percent_iterator_reg``` register when ```percent_iterator``` reaches 100.\n",
    "\n",
    "    else if (meta.percent_iterator == 100) {\n",
    "        meta.percent_iterator = 0;\n",
    "        percent_iterator_reg.write(0, meta.percent_iterator);\n",
    "    }\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_01_13.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Save the changes by pressing ```Ctrl+s```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960d1cf-1a03-4df4-82f2-487d9f1405e8",
   "metadata": {},
   "source": [
    "## Step 6.2: Modifying the headers file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02e8ce-fd72-41a8-9ff3-021a52dabbbf",
   "metadata": {},
   "source": [
    "Click on [headers.p4](./labs_files/SYN/headers.p4) to open the I/O file in the editor.\n",
    "\n",
    "<div style=\"background-color: #e0f7fa; border: 1px solid #b2ebf2; padding: 10px; border-radius: 5px;\">\n",
    "In the PNA architecture of P4, variables needed in the body of the control block will have to be declared as metadata. </div>\n",
    "\n",
    "Associate each declared register with a variable in the metadata structure by adding the following code.\n",
    "\n",
    "    bit<7> drop_percent;\n",
    "    bit<32> syn_counts;\n",
    "    bit<7> percent_iterator;\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/6_02_00.png\" width=\"650\"><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Save the changes by pressing ```Ctrl+s```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7cab7e-14e4-402d-91e1-73bedbd386d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 7: Compiling the P4 program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a90f1-e8bd-4c80-b925-af1777485a3f",
   "metadata": {},
   "source": [
    "In this lab, we will not modify the P4 code in which we implement a simple packet reflector. Instead, we will just compile it using the p4c-dpdk compiler. Note that in this P4 code the Portable NIC Architecture (PNA) is used.\n",
    "\n",
    "To upload and compile the P4 program, issue the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8803fdf-3b6d-4b54-b88e-53ac463dfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # server2.upload_file('labs_files/SYN/headers.p4','headers.p4')\n",
    "# server2.upload_file('scripts/run/SYN/headers.p4','headers.p4')\n",
    "# server2.upload_file('labs_files/SYN/parser.p4','parser.p4')\n",
    "# server2.upload_file('labs_files/SYN/precontrol.p4','precontrol.p4')\n",
    "# # server2.upload_file('labs_files/SYN/control.p4','control.p4')\n",
    "# server2.upload_file('scripts/run/SYN/control.p4','control.p4')\n",
    "# server2.upload_file('labs_files/SYN/deparser.p4','deparser.p4')\n",
    "# server2.upload_file('labs_files/SYN/main.p4','main.p4')\n",
    "# stdout, stderr = server2.execute(f'sudo p4c-dpdk --arch=pna main.p4 -o syn.spec')\n",
    "# stdout, stderr = server2.execute(f'ls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b551543-8fb0-477a-a038-e935f2e94804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m sudo: unable to resolve host server2: Name or service not known\n",
      " \u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SFTPAttributes: [ size=556 uid=1000 gid=1000 mode=0o100664 atime=1729191130 mtime=1729191131 ]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server2.upload_file('experiments/reflector/reflector.p4','reflector.p4')\n",
    "stdout, stderr = server2.execute(f'sudo p4c-dpdk --arch=pna reflector.p4 -o reflector.spec')\n",
    "server2.upload_file('experiments/reflector/ethdev0.io','ethdev0.io')\n",
    "server2.upload_file('experiments/reflector/reflector.cli','reflector.cli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0c604-80b6-4c11-b847-d501f3293de0",
   "metadata": {},
   "source": [
    "The command above invokes the ```p4c-dpdk``` compiler to compile the ```main.p4``` program and generates the ```lab9.spec``` file which is a specification file needed to run the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e2e98-644f-4fc3-88ff-123b50aaf8d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 8: Running the P4-DPDK pipeline\n",
    "Now that all the required scripts are prepared, we can run the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90261c-2809-4f90-8e56-dcbe57f90239",
   "metadata": {},
   "source": [
    "## Step 8.1: Uploading files\n",
    "The following code uploads the CLI and I/O scripts to server1 and server2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "669fc8a7-d84d-4bf1-b22a-fc6ba823f7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SFTPAttributes: [ size=1183 uid=1000 gid=1000 mode=0o100664 atime=1729001524 mtime=1729001524 ]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server2.upload_file('labs_files/SYN/syn.cli','syn.cli')\n",
    "server2.upload_file('labs_files/SYN/ethdev0.io','ethdev0.io')\n",
    "server2.upload_file('labs_files/SYN/ethdev1.io','ethdev1.io')\n",
    "server2.upload_file('labs_files/SYN/ethdev2.io','ethdev2.io')\n",
    "server2.upload_file('labs_files/SYN/ethdev3.io','ethdev3.io')\n",
    "server2.upload_file('labs_files/SYN/rules.txt','rules.txt')\n",
    "server2.upload_file('labs_files/SYN/reset_SYN_packets_per_second.py','reset_SYN_packets_per_second.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f903f-69d4-47cf-b90d-d2afda7112d9",
   "metadata": {},
   "source": [
    "## Step 8.2: Reserving hugepages\n",
    "Configure the number of hugepages in the system by typing the following command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ab66bf2-349a-4f26-9a61-b1fefb7a9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []\n",
    "\n",
    "for server in servers:\n",
    "    threads.append(server.execute_thread(f' sudo sh -c  \"echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages\"'))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dff55-e3e9-41f7-b6b4-47f4e07d0948",
   "metadata": {},
   "source": [
    "Hugepage reservation is done by setting the number of hugepages required to the ```nr_hugepages``` file in the kernel corresponding to a specific page size (in Kilobytes).\n",
    "\n",
    "The ```echo``` command is used to print a value which in this case is ```1024``` representing the number of hugepages. The ```>``` symbol is a redirection operator that redirects the output of the previous command (echo 1024) to the file specified in the following path: ```/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5042869-7da4-46db-9824-228bd5188d8e",
   "metadata": {},
   "source": [
    "## Step 8.3: Opening a terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "Copy the output of the command below and paste it in the terminal to enter to server2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d153fc4-f4a3-426f-8e73-f63047a8af5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'server2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mserver2\u001b[49m\u001b[38;5;241m.\u001b[39mget_ssh_command()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'server2' is not defined"
     ]
    }
   ],
   "source": [
    "server2.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3de87-26c3-47b2-9fe3-5c1429da4094",
   "metadata": {},
   "source": [
    "## Step 8.4: Running the pipeline\n",
    "\n",
    "Run the following commands in the terminal:\n",
    "    \n",
    "    cd dpdk\n",
    "    sudo examples/pipeline/build/pipeline -c 0x1F -- -s /home/ubuntu/syn.cli\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/pipeline.png\" width=\"900\"><br>\n",
    "\n",
    "In the figure above, the command is used to run the DPDK pipeline application considering the following arguments:\n",
    "\n",
    "\t```examples/pipeline/build/pipeline```: the path to the executable DPDK pipeline application.<br>\n",
    "\t```-c```: this parameter is used to specify the hexadecimal bitmask of the cores to run on. In this case, (0x1F) indicated that 4 cores are reserved for the pipelines and one extra core is needed for other processes.<br>\n",
    "\t```-s```: this parameter is used to specify the path to the CLI script file to be run at application startup ```/home/ubuntu/syn.cli```.<br>\n",
    "\n",
    "Note that when the DPDK pipeline runs, the CLI script is printed in the terminal. If any problems are encountered while running the pipeline, error messages will be shown within the printed CLI script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a36242c-6543-4e15-9cbf-00e30ac4cad9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setp 9: Testing the application\n",
    "To test the application, we will send from server1 packets at a high rate to server2 using a DPDK-based packet generation tool called pktgen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36423bba-b0b3-4c3c-b482-be5b51c8cd19",
   "metadata": {},
   "source": [
    "## Step 9.1: Opening a new terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "Copy the output of the command below and paste it in the terminal to enter to server2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "593ef5fb-d71e-4d43-96a9-91a681ccb72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3090:f816:3eff:fe44:e9de'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server2.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1895b-fd17-40f6-b3a7-0a13ca917ec8",
   "metadata": {},
   "source": [
    "## Step 9.2: Reset packet count every one second\n",
    "\n",
    "Type the command below to reset the count of SYN packets every second.\n",
    "\n",
    "    sudo python3 reset_SYN_packets_per_second.py\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/reset_reg.png\" width=\"800px\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e40eb6-5241-4192-a801-65b3d1dbe02a",
   "metadata": {},
   "source": [
    "## Step 9.3: Opening a new terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "Copy the output of the command below and paste it in the terminal to enter to server1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "119e8310-c962-4440-863f-15b150a0e0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3090:f816:3eff:fe7f:ec1e'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server1.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa1d34-d0b0-435a-a133-73c565114988",
   "metadata": {},
   "source": [
    "## Step 9.4: Running pktgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fb7cc-e18e-4144-9376-c5a7937d80d2",
   "metadata": {},
   "source": [
    "Run the command below to know which interface is being used on server 1 to communicate with server 2 and server 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2452b58-8b01-405b-861f-118ba384dea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:00.0\n"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server1.execute('lspci | grep ConnectX | awk \\'{print $1}\\'| head -n 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec771b81-7729-42a1-aaa6-886e166de798",
   "metadata": {},
   "source": [
    "The output of this command will be used to refer to the interface ID in the command invoked to run pktgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754e213-e91b-40f0-bd4b-8f86bbfa82ac",
   "metadata": {},
   "source": [
    "Run the following commands in the terminal to run pktgen:\n",
    "\n",
    "<div style=\"background-color: #e0f7fa; border: 1px solid #b2ebf2; padding: 10px; border-radius: 5px;\">\n",
    "It is important that the interface name matches the output of the previous command. This is an example where the interface ID is 07:00.0\n",
    "</div>\n",
    "\n",
    "    sudo pktgen -l 0,1 -n 4 -a 07:00.0 -- -P -m \"1.0\"\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/pktgen_command.png\" width=\"650\"><br>\n",
    "\n",
    "In the figure above, the command ```pktgen``` is used to run the packet generator considering the following arguments:\n",
    "\n",
    "\t```-l```: List of cores to run on.<br>\n",
    "\t```-n```: Number of memory channels.<br>\n",
    "\t```-a```: The ID of allowed interfaces (the command shows an example where interface 07:00.0 is used).<br>\n",
    "\t```-P```: Enable promiscuous mode on all ports.<br>\n",
    "\t```-m```: Matrix for mapping ports to logical cores.<be>\n",
    "\n",
    "In this step, we are invoking pktgen, using cores 2 cores (0 and 1) as specified in the ```-l``` parameter with 4 memory channels as specified in the ```-n``` parameter. The interface allowed ```-a``` has the ID 07:00.0 in this example. We enabled promiscuous mode ```-P``` and mapped CPU core 1 to handle the rx and tx ports of port 0 as specified in the ```-m``` parameter.\n",
    "\n",
    "As soon a pktgen starts the main screen is displayed:\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_main.png\" width=\"650\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a177778-8a26-4f75-8f48-82cda4df0e61",
   "metadata": {},
   "source": [
    "## Step 9.5: Configuring pktgen\n",
    "\n",
    "In pktgen, we will set the source and destination MAC and IP addresses along with the desired packet size of the generated packets. RSS will distribute packets that belong to the same flow on each of the four different pipelines running on four different cores. Therefore, we will have to generate the packets from a range of flows. To do so, we will generate packets from a range of source and destination IP addresses. \n",
    "\n",
    "In pktgen terminal, enter the following command to navigate the page displaying the settings of packets sent from a range of flows:\n",
    "\n",
    "    page range\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_range.png\" width=\"650\"><be>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to set the source MAC address:\n",
    "\n",
    "    range 0 src mac start 00:00:00:00:00:01\n",
    "    range 0 src mac min 00:00:00:00:00:01\n",
    "    range 0 src mac max 00:00:00:00:00:01\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_srcmac.png\" width=\"650\"><be>\n",
    "\n",
    "To modify the settings in the rage page we used the ```range``` command. To set the source MAC address of the generated packets sent from port ID 0, we used the ```src mac``` command and since the source MAC addresses are not randomized, we will set the starting value ```start```, minimum value ```min``` and maximum value ```max``` to be ```00:00:00:00:00:01``` which is the MAC address of server1. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to set the destination MAC address:\n",
    "\n",
    "    range 0 dst mac start 00:00:00:00:00:21\n",
    "    range 0 dst mac min 00:00:00:00:00:21\n",
    "    range 0 dst mac max 00:00:00:00:00:21\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_dstmac.png\" width=\"850\"><be>\n",
    "\n",
    "To modify the settings in the rage page we used the ```range``` command. To set the destination MAC address of the generated packets sent from port ID 0, we used the ```dst mac``` command and since the destination MAC addresses are not randomized, we will set the starting value ```start```, minimum value ```min``` and maximum value ```max``` to be ```00:00:00:00:00:21``` which is the MAC address of the interface on server2 facing server1. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to set the source IP address:\n",
    "\n",
    "    range 0 src ip start 1.1.1.1\n",
    "    range 0 src ip min 1.1.1.1\n",
    "    range 0 src ip max 250.250.250.250\n",
    "    range 0 src ip inc 0.0.0.1\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_srcip.png\" width=\"850\"><be>\n",
    "\n",
    "To modify the settings in the rage page we used the ```range``` command. To set the source IP address of the generated packets sent from port ID 0, we used the ```src ip``` command. The starting value ```start``` and minimum value ```min``` are both set as the IP ```1.1.1.1```. The rage will reach a maximum value ```max``` to be ```250.250.250.250``` by incrementing each octet by ```0.0.0.1``` and specified in the ```inc```. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to set the destination IP address:\n",
    "\n",
    "    range 0 dst ip start 192.168.20.1\n",
    "    range 0 dst ip min 192.168.20.1\n",
    "    range 0 dst ip max 192.168.20.1\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_dstip.png\" width=\"850\"><be>\n",
    "\n",
    "To modify the settings in the rage page we used the ```range``` command. To set the destination IP address of the generated packets sent from port ID 0, we used the ```dst ip``` command and since the destination IP addresses are not randomized, we will set the starting value ```start```, minimum value ```min``` and maximum value ```max``` to be ```192.168.20.1``` which is the IP address of the interface on server3.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to set the packet size:\n",
    "\n",
    "    range 0 size start 1500\n",
    "    range 0 size min 1500\n",
    "    range 0 size max 1500\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_size.png\" width=\"850\"><be>\n",
    "\n",
    "To modify the settings in the rage page we used the ```range``` command. To set the size in bytes of the generated packets sent from port ID 0, we used the ```size``` command and since the packet size is not randomized, we will set the starting value ```start```, minimum value ```min``` and maximum value ```max``` to be ```1500``` to set the packet size to 1500 bytes. \n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following commands to clear all flags in the TCP header and set the SYN flag to 1:\n",
    "\n",
    "    range 0 tcp flag clr all\n",
    "    range 0 tcp flag set syn\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_tcp.png\" width=\"850\"><be>\n",
    "\n",
    "<hr>\n",
    "\n",
    "Enter the following command to enable generating packets from a range of flows and going back to the main page:\n",
    "\n",
    "    enable 0 range\n",
    "    page main\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_enable.png\" width=\"650\"><be>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1887e-a855-4a5e-a0de-23b5c9e071e3",
   "metadata": {},
   "source": [
    "## Step 9.6: Start sending packets\n",
    "\n",
    "In pktgen terminal execute the following commands to start generating and sending packets from server 1 to server 3:\n",
    "\n",
    "    start 0\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_start.png\" width=\"850\"><br>\n",
    "\n",
    "To start sending packets, we used the ```start``` command followed by the port list. In this case, we are using one port with ID 0. We can observe the rate at which the packets are sent from server 1 to server3. In the grey box, the first two lines display the number of packets sent and received per second, and the last line displays the sending and receiving throughput in Mbyte per second. The result in the screenshot above shows that pktgen is generating around 8 million packets at a rate close to 100 Gbyte per second. These packets are sent to server 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf64a1-08ff-4201-b49c-04d3d32b7c1c",
   "metadata": {},
   "source": [
    "## Step 9.7: Opening a new terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "Copy the output of the command below and paste it in the terminal to enter to server3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddda69e4-aa23-499f-9b67-8d3cf2a43899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3090:f816:3eff:feb3:4195'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server3.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020562f6-58b2-4eed-b0e6-fcf086fe5f2d",
   "metadata": {},
   "source": [
    "## Step 9.8: Running pktgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293b07f-2b23-4dc5-ae8a-54386da7842e",
   "metadata": {},
   "source": [
    "Run the command below to know which interface is being used on server 3 to communicate with server 1 and server 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a821b257-378c-4d1d-99ae-b2dab5783e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:00.0\n"
     ]
    }
   ],
   "source": [
    "stdout, stderr = server3.execute('lspci | grep ConnectX | awk \\'{print $1}\\'| head -n 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6f5b5-4433-4501-8c1a-415c1558bb5f",
   "metadata": {},
   "source": [
    "The output of this command will be used to refer to the interface ID in the command invoked to run pktgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95250f-04ba-4017-a261-44eb7b51de05",
   "metadata": {},
   "source": [
    "Run the following commands in the terminal to run pktgen:\n",
    "\n",
    "<div style=\"background-color: #e0f7fa; border: 1px solid #b2ebf2; padding: 10px; border-radius: 5px;\">\n",
    "It is important that the interface name matches the output of the previous command. This is an example where the interface ID is 07:00.0\n",
    "</div>\n",
    "\n",
    "    sudo pktgen -l 0,1 -n 4 -a 07:00.0 -- -P -m \"1.0\"\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/pktgen_command2.png\" width=\"850\"><br>\n",
    "\n",
    "As soon a pktgen starts the main screen is displayed:\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_main2.png\" width=\"850\"><br>\n",
    "\n",
    "The figure above shows that h3 is receiving around 8 million SYN packets per second.\n",
    "\n",
    "Note that no packets are dropped by the pipeline because the dropping percentage is set\n",
    "to zero. The drop_percent_reg register by default holds the value 0. We will now configure\n",
    "the dropping rate from the control plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1aab38-db6e-4f3d-a598-18726963e9b0",
   "metadata": {},
   "source": [
    "## Step 9.9: Opening a new terminal\n",
    "\n",
    "Launch a new terminal by opening a new tab and then select \"terminal\".\n",
    "\n",
    "Copy the output of the command below and paste it in the terminal to enter to server2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af722771-6978-42ce-813c-8fa21c689eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssh -i /home/fabric/work/fabric_config/slice_key -F /home/fabric/work/fabric_config/ssh_config ubuntu@2001:400:a100:3090:f816:3eff:fe44:e9de'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server2.get_ssh_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d42b5-feb6-461d-aa95-45e4bbfa5c7c",
   "metadata": {},
   "source": [
    "## Step 9.10: Opening the pipeline CLI\n",
    "\n",
    "Enter the pipeline CLI by typing the following command.\n",
    "\n",
    "    telnet 0.0.0.0 8086\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/telnet.png\" width=\"700\"><br>\n",
    "\n",
    "The ```telnet``` command is followed by the IP address of the server (0.0.0.0) and the port\n",
    "number (8086)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc08b96-49c8-48f3-b4a2-be0ec714beab",
   "metadata": {},
   "source": [
    "## Step 9.11: Configuring the drop rate\n",
    "\n",
    "Configure the dropping rate to be 50% by typing the command below.\n",
    "\n",
    "    pipeline PIPELINE0 regwr drop_percent_reg_0 value 50 index 0\n",
    "    pipeline PIPELINE1 regwr drop_percent_reg_0 value 50 index 0\n",
    "    pipeline PIPELINE2 regwr drop_percent_reg_0 value 50 index 0\n",
    "    pipeline PIPELINE3 regwr drop_percent_reg_0 value 50 index 0\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/drop50.png\" width=\"800\"><br>\n",
    "\n",
    "The ```regwr``` command writes a value to the register drop_percent_reg at a specific index.\n",
    "Therefore, this command takes two inputs ```value``` 50 and the ```index``` 0. 0x32 is the\n",
    "hexadecimal representation of 50. The following is applied to all pipelines.\n",
    "\n",
    "Note that the p4c-dpdk compiler adds (_0) to the labels of the registers defined in the P4\n",
    "code. Therefore, drop_percent_reg is compiled as drop_percent_reg_0 in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8d66a-a430-41c8-aa57-b56b396e0b43",
   "metadata": {},
   "source": [
    "## Step 9.12: Inspecting the number of SYN packets\n",
    "\n",
    "Inspect the number of received SYN packet received by server 3 by observing the pktgen monitor\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_drop50.png\" width=\"650\"><br>\n",
    "\n",
    "The figure above shows that h3 is receiving around 4.5 million SYN packets per second.\n",
    "\n",
    "Because the received number of SYN packets per second is around 8 million, and the threshold\n",
    "is 1 million, the dropping threshold will be applied to 7 million packets only (8M - 1M). Note that\n",
    "the pipeline does not apply the dropping mechanism on the first 1 million SYN packets. By\n",
    "setting the dropping percentage to 50%, we expect to receive 1M + 7M/2 SYN packets,\n",
    "which is around 4.5 million packets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66a5d9-9a29-4f50-87e2-bee22ee31db7",
   "metadata": {},
   "source": [
    "## Step 9.13: Configuring the drop rate\n",
    "\n",
    "In the telnet terminal, configure the dropping rate to be 100% by typing the command below.\n",
    "\n",
    "    pipeline PIPELINE0 regwr drop_percent_reg_0 value 100 index 0\n",
    "    pipeline PIPELINE1 regwr drop_percent_reg_0 value 100 index 0\n",
    "    pipeline PIPELINE2 regwr drop_percent_reg_0 value 100 index 0\n",
    "    pipeline PIPELINE3 regwr drop_percent_reg_0 value 100 index 0\n",
    "    \n",
    "<img src=\"./labs_files/SYN/figs/drop100.png\" width=\"700\"><br>\n",
    "\n",
    "By setting the dropping threshold to 100%, the expected number of SYN packets to be\n",
    "received per second is around 1 million because all the packets above the threshold will be\n",
    "dropped. 0x64 is the hexadecimal representation of 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb840cc2-7f03-4e6e-bfde-9bf16b861b05",
   "metadata": {},
   "source": [
    "## Step 9.14: Inspecting the number of SYN packets\n",
    "\n",
    "Inspect the number of received SYN packet received by server 3 by observing the pktgen monitor\n",
    "\n",
    "<img src=\"./labs_files/SYN/figs/pktgen_drop100.png\" width=\"650\"><br>\n",
    "\n",
    "The figure above shows that h3 is receiving around 1 million SYN packets per second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6dd26-c20c-4c25-96c2-1b2f1aaaeca9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Step 10: Delete the slice\n",
    "\n",
    "This concludes Lab 9. Please delete your slice when you are done with your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f27f3fc-004f-46c2-984c-8c2a90883eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/fabric_cm/credmgr/swagger_client/rest.py:45: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.\n",
      "  return self.urllib3_response.getheaders()\n"
     ]
    },
    {
     "ename": "SliceManagerException",
     "evalue": "Internal Server Error - (invalid_grant) expired refresh token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSliceManagerException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed/slice_manager/slice_manager.py:224\u001b[0m, in \u001b[0;36mSliceManager.refresh_tokens\u001b[0;34m(self, refresh_token)\u001b[0m\n\u001b[1;32m    223\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m Utils\u001b[38;5;241m.\u001b[39mextract_error_message(exception\u001b[38;5;241m=\u001b[39mtokens)\n\u001b[0;32m--> 224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SliceManagerException(error_message)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mSliceManagerException\u001b[0m: Internal Server Error - (invalid_grant) expired refresh token",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSliceManagerException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfabrictestbed_extensions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfablib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfablib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FablibManager \u001b[38;5;28;01mas\u001b[39;00m fablib_manager\n\u001b[0;32m----> 2\u001b[0m fablib \u001b[38;5;241m=\u001b[39m \u001b[43mfablib_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m=\u001b[39m fablib\u001b[38;5;241m.\u001b[39mget_slice(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP4DPDK_HH3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# slice.delete()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:688\u001b[0m, in \u001b[0;36mFablibManager.__init__\u001b[0;34m(self, fabric_rc, credmgr_host, orchestrator_host, core_api_host, token_location, project_id, bastion_username, bastion_key_location, log_level, log_file, data_dir, output, execute_thread_pool_size, offline, auto_token_refresh, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssh_thread_pool_executor \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(execute_thread_pool_size)\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_logging()\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__build_slice_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_check()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:1075\u001b[0m, in \u001b[0;36mFablibManager.__build_slice_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1074\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(e, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1075\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_manager\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed_extensions/fablib/fablib.py:1058\u001b[0m, in \u001b[0;36mFablibManager.__build_slice_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m Utils\u001b[38;5;241m.\u001b[39mis_reachable(hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_orchestrator_host())\n\u001b[1;32m   1056\u001b[0m Utils\u001b[38;5;241m.\u001b[39mis_reachable(hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_core_api_host())\n\u001b[0;32m-> 1058\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_manager \u001b[38;5;241m=\u001b[39m \u001b[43mSliceManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43moc_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_orchestrator_host\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcm_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_credmgr_host\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_api_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_core_api_host\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_project_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_refresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_token_refresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_manager\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[1;32m   1069\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlice manager initialized!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed/slice_manager/slice_manager.py:95\u001b[0m, in \u001b[0;36mSliceManager.__init__\u001b[0;34m(self, cm_host, oc_host, core_api_host, token_location, project_id, scope, initialize, project_name, auto_refresh)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SliceManagerException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid initialization parameters: project_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m                                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialize:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed/slice_manager/slice_manager.py:113\u001b[0m, in \u001b[0;36mSliceManager.initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03mInitialize the Slice Manager object\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m- Load the tokens\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m- Refresh if needed\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed/slice_manager/slice_manager.py:160\u001b[0m, in \u001b[0;36mSliceManager.__load_tokens\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Renew the tokens to ensure any project_id changes are taken into account\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_refresh \u001b[38;5;129;01mand\u001b[39;00m refresh_token:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefresh_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_token\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fabrictestbed/slice_manager/slice_manager.py:227\u001b[0m, in \u001b[0;36mSliceManager.refresh_tokens\u001b[0;34m(self, refresh_token)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m Utils\u001b[38;5;241m.\u001b[39mextract_error_message(exception\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SliceManagerException(error_message)\n",
      "\u001b[0;31mSliceManagerException\u001b[0m: Internal Server Error - (invalid_grant) expired refresh token"
     ]
    }
   ],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()\n",
    "slice = fablib.get_slice(name=\"P4DPDK_HH3\")\n",
    "# slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5401abb-9a78-4712-8d65-db437d63bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager()\n",
    "slice = fablib.get_slice(name=\"P4DPDK_HH4\")\n",
    "# slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a355950-ad56-4011-930e-e6868cb72e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "servers = []\n",
    "\n",
    "servers.append(slice.get_node(name=\"server1\"))     \n",
    "servers.append(slice.get_node(name=\"server2\"))\n",
    "servers.append(slice.get_node(name=\"switch\"))     \n",
    "servers.append(slice.get_node(name=\"server3\"))\n",
    "servers.append(slice.get_node(name=\"server4\"))     \n",
    "servers.append(slice.get_node(name=\"server5\"))     \n",
    "servers.append(slice.get_node(name=\"server6\"))     \n",
    "\n",
    "server1 = servers[0]\n",
    "server2 = servers[1]\n",
    "switch = servers[2]\n",
    "server3 = servers[3]\n",
    "server4 = servers[4]\n",
    "server5 = servers[5]\n",
    "server6 = servers[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e3d97-a261-4c00-984c-2750cbd45064",
   "metadata": {
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "1.\tNETSCOUT, What is a Volumetric Attack? [Online]. Available: https://www.netscout.com/what-is-ddos/volumetric-attacks\n",
    "2.\tCloudflare, SYN Flood Attack. [Online]. Available: https://www.cloudflare.com/learning/ddos/syn-flood-ddos-attack/\n",
    "3.\tGURU99, What is TCP Three-Way HandShake?. [Online]. Available: https://www.guru99.com/tcp-3-way-handshake.html\n",
    "4.\tNETSCOUT, What is a SYN flood attack and how do you to prevent it? [Online]. Available: https://www.netscout.com/what-is-ddos/syn-flood-attacks\n",
    "5.\tThe P4 Language Consortium, P4 Portable NIC Architecture (PNA), Version 0.5, 2021. [Online]. Available: https://p4.org/p4-spec/docs/PNA.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
